# extract_embeddings_sampled_1000.py

import os
import json
import pandas as pd
import torch
from tqdm import tqdm
import numpy as np
from transformers import TapasTokenizer, TapasModel
import warnings
import random

# å¿½ç•¥è­¦å‘Š
warnings.simplefilter(action='ignore', category=FutureWarning)

os.environ['LOKY_MAX_CPU_COUNT'] = '12'  # é˜²æ­¢ joblib å¤šè¿›ç¨‹è­¦å‘Š


class TableEmbedder:
    """
    ä½¿ç”¨ TAPAS æ¨¡å‹å¯¹è¡¨æ ¼è¿›è¡ŒåµŒå…¥ã€‚
    """
    def __init__(self, model_name="google/tapas-base", device=None):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ğŸš€ Using device: {self.device}")
        self.tokenizer = TapasTokenizer.from_pretrained(model_name)
        self.model = TapasModel.from_pretrained(model_name).to(self.device)

    def embed_table(self, table: pd.DataFrame):
        """
        å°†è¡¨æ ¼è½¬æ¢ä¸ºåµŒå…¥å‘é‡ã€‚

        Args:
            table (pd.DataFrame): è¾“å…¥è¡¨æ ¼ã€‚

        Returns:
            np.ndarray: åµŒå…¥å‘é‡ (768,)
        """
        table = table.astype(str).fillna("")
        try:
            inputs = self.tokenizer(
                table=table,
                queries=["What is in the table?"],  # å›ºå®šæŸ¥è¯¢
                return_tensors="pt",
                truncation=True,
                padding="max_length",
                max_length=512
            ).to(self.device)
            with torch.no_grad():
                outputs = self.model(**inputs)
            embedding = outputs.last_hidden_state[:, 0, :].squeeze(0).cpu().numpy()
            return embedding
        except Exception as e:
            print(f"âŒ TAPAS encoding failed: {e}")
            return np.zeros(self.model.config.hidden_size)  # è¿”å›é›¶å‘é‡å®¹é”™


class SampledCSVEmbedder:
    """
    ä¸“é—¨ç”¨äºå¤„ç† CSV æ–‡ä»¶å¤¹ï¼Œéšæœºé‡‡æ · 1000 ä¸ªæ–‡ä»¶å¹¶æå–åµŒå…¥ã€‚
    """
    def __init__(self, csv_folder: str, save_path: str, base_path: str = None, sample_size: int = 1000):
        """
        :param csv_folder: åŒ…å«æ‰€æœ‰ CSV çš„æ–‡ä»¶å¤¹è·¯å¾„
        :param save_path: è¾“å‡º JSON ä¿å­˜è·¯å¾„
        :param base_path: ç”¨äºç”Ÿæˆç›¸å¯¹è·¯å¾„çš„æ ¹è·¯å¾„
        :param sample_size: éšæœºé‡‡æ ·æ•°é‡
        """
        self.csv_folder = csv_folder
        self.save_path = save_path
        self.base_path = base_path or csv_folder
        self.sample_size = sample_size
        self.embedder = TableEmbedder()
        self.results = []

    def process_all_csvs(self):
        """
        éšæœºé‡‡æ ·æŒ‡å®šæ•°é‡çš„ CSV æ–‡ä»¶å¹¶æå–åµŒå…¥ã€‚
        """
        if not os.path.exists(self.csv_folder):
            raise FileNotFoundError(f"CSV folder not found: {self.csv_folder}")

        all_files = [f for f in os.listdir(self.csv_folder) if f.endswith(".csv")]
        if len(all_files) == 0:
            print(f"âš ï¸ No CSV files found in {self.csv_folder}.")
            return

        # ğŸ” éšæœºé‡‡æ ·æœ€å¤š sample_size ä¸ªæ–‡ä»¶
        sampled_files = random.sample(all_files, min(self.sample_size, len(all_files)))
        print(f"ğŸ“Š Found {len(all_files)} CSVs, sampling {len(sampled_files)} files...")

        for file_name in tqdm(sampled_files, desc="Processing sampled CSVs"):
            file_path = os.path.join(self.csv_folder, file_name)
            try:
                # è¯»å–è¡¨æ ¼
                table = pd.read_csv(file_path, dtype=str).fillna("")  # ç»Ÿä¸€å¤„ç†ç¼ºå¤±å€¼
                embedding = self.embedder.embed_table(table)
                relative_path = os.path.relpath(file_path, self.base_path).replace("\\", "/")

                self.results.append({
                    "file_name": relative_path,
                    "embedding": embedding.tolist(),
                    "tsne": []  # ç•™ç©ºï¼Œä¾›åç»­ t-SNE ä½¿ç”¨
                })
            except Exception as e:
                print(f"âŒ Error processing {file_path}: {e}")

        print(f"âœ… Successfully embedded {len(self.results)} sampled files.")

    def save(self):
        """
        ä¿å­˜ç»“æœåˆ° JSON æ–‡ä»¶ã€‚
        """
        os.makedirs(os.path.dirname(self.save_path), exist_ok=True)
        with open(self.save_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"âœ… Embeddings saved to: {self.save_path}")
        print(f"ğŸ“¦ Total embedded files: {len(self.results)}")


def main():
    # ================================
    # ğŸ”§ ç”¨æˆ·é…ç½®åŒº
    # ================================
    csv_folder = r"X:\UniversityCourseData\Visualization\20250628TSneå¯è§†å¯¹æ¯”\ChartBench\CSV"
    save_path = "X:/UniversityCourseData/Visualization/20250628TSneå¯è§†å¯¹æ¯”/t-SNE/output/CSV/ChartBench.json"
    sample_size = 800  # éšæœºé‡‡æ · 1000 ä¸ªæ–‡ä»¶

    # ================================
    # âœ… æ‰§è¡Œï¼šé‡‡æ · + æå–åµŒå…¥
    # ================================
    processor = SampledCSVEmbedder(
        csv_folder=csv_folder,
        save_path=save_path,
        base_path=csv_folder,
        sample_size=sample_size
    )
    processor.process_all_csvs()
    processor.save()


if __name__ == "__main__":
    main()